#loading data
import tensorflow as tf
import os
import random
import threading
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.optimizers import Adam
from tqdm import tqdm
tf.debugging.set_log_device_placement(False)

def LoadData():
    random.seed(2020)
    number = 0
    data = []
    data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)),'data', '0')
    for files in tqdm(os.listdir(data_dir)):
        p = os.path.join(data_dir, files)
    n = np.load(p)
    data.append([n, '0'])
    number+=1
    data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)),'data', '1')
    for files in tqdm(os.listdir(data_dir)):
        p = os.path.join(data_dir, files)
        n = np.load(p)
        data.append([n, '1'])
        number+=1
    random.shuffle(data)
    X_train, y_train, X_test, y_test = [], [], [] ,[]
    for i in range(0, int(number*0.8)):
        X_train.append(data[i][0])
        y_train.append(data[i][1])
    for i in range(int(number*0.8), number):
        X_test.append(data[i][0])
        y_test.append(data[i][1])
    del(data)
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    X_test = np.array(X_test)
    y_test = np.array(y_test)
    # 데이터를 -1 ~ 1 사이 값으로 normalization 진행
    X_train = (X_train.astype(np.float32) - 0.5)
    X_test = (X_test.astype(np.float32) - 0.5)
    # X_train 의 shape 를 (60000, 28, 28) -> (60000, 784) 변경
    # 우리가 한 row 당 784 columns 가진다
    X_train = X_train.reshape(len(X_train), 65536)
    X_test = X_test.reshape(len(X_test), 65536)
    print(f"Shape of X_train --> {X_train.shape}")
    return (X_train, y_train, X_test, y_test)


# optimizer function Adam 사용
def GetOptimizer():
    return Adam(lr=0.0002, beta_1=0.5)

# Generator 만들기
def GetGenerator():
    generator = Sequential()
    generator.add(Dense(256, input_dim=100))
    generator.add(LeakyReLU(0.2))

    generator.add(Dense(512))
    generator.add(LeakyReLU(0.2))

    generator.add(Dense(1024))
    generator.add(LeakyReLU(0.2))

    generator.add(Dense(65536, activation="tanh"))

    generator.compile(loss="binary_crossentropy", optimizer=GetOptimizer())
    generator.summary()
    return generator

# Discriminator 만들기
def GetDiscriminator():
    discriminator = Sequential()
    discriminator.add(Dense(1024, input_dim=65536))
    discriminator.add(LeakyReLU(0.2))
    discriminator.add(Dropout(0.3))

    discriminator.add(Dense(512))
    discriminator.add(LeakyReLU(0.2))
    discriminator.add(Dropout(0.3))

    discriminator.add(Dense(256))
    discriminator.add(LeakyReLU(0.2))
    discriminator.add(Dropout(0.3))

    discriminator.add(Dense(1, activation="sigmoid"))
    discriminator.compile(loss="binary_crossentropy", optimizer=GetOptimizer())
    discriminator.summary()
    return discriminator

def GetGanNetwork(Discriminator, Generator):
    Discriminator.trainable = False
    gan_input = Input(shape=(100, ))

    x = Generator(gan_input)

    gan_output = Discriminator(x)
    gan = Model(inputs=gan_input, outputs=gan_output)
    gan.compile(loss="binary_crossentropy", optimizer=GetOptimizer())
    return gan

def PlotGeneratedImage(epoch, generated, examples=100, dim=(10, 10), figsize=(10, 10)):
    noise = np.random.normal(0, 1, size=[examples, 100])
    generated_images = generated.predict(noise)
    generated_images = generated_images.reshape(examples, 256, 256)
    plt.figure(figsize=figsize)
    for i in range(generated_images.shape[0]):
        plt.subplot(dim[0], dim[1], i+1)
        plt.imshow(generated_images[i], interpolation="nearest", cmap="gray_r")
        plt.axis("off")
    plt.tight_layout()
    plt.savefig("GAN_image_epochs_%d.png" % epoch)

def Train(epochs=1, batch_size=128):
    (X_train, y_train, X_test, y_test) = LoadData()
    batch_count = X_train.shape[0] // batch_size

    generator = GetGenerator()
    discriminator = GetDiscriminator()
    gan = GetGanNetwork(discriminator, generator)
    for e in range(1, epochs+1):
        print('-'*15, 'Epoch %d' % e, '-'*15)
        for _ in tqdm(range(batch_count)):
            # 입력으로 사용할 random 노이즈하고 이미지 가져오기
            noise = np.random.normal(0, 1, [batch_size, 100])

            generator_images = generator.predict(noise)

            image_bacth = X_train[np.random.randint(low=0, high=X_train.shape[0], size=batch_size)]

            X = np.concatenate([image_bacth, generator_images])

            y_dis = np.zeros(2*batch_size)
            y_dis[:batch_size] = 0.9

            discriminator.trainable = False
            discriminator.train_on_batch(X, y_dis)

            y_gan = np.ones(batch_size)
            discriminator.trainable = False
            gan.train_on_batch(noise, y_gan)

        if e == 1 or e % 20 == 0:
            PlotGeneratedImage(e, generator)


if __name__ == "__main__":
    Train(400, 128)
